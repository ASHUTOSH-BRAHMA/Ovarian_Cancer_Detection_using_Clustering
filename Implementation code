
import os
import shutil
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE
from tqdm import tqdm
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

DATA_PATH = "/kaggle/input/ovarian-cancer-detection/Ovarian Cancer Dataset For project"
OUTPUT_PATH = "/kaggle/working/clustered_data"

print("Total images:", len(os.listdir(DATA_PATH)))

if os.path.exists(OUTPUT_PATH):
    shutil.rmtree(OUTPUT_PATH)
os.makedirs(OUTPUT_PATH)

IMG_SIZE = 224
base_model = DenseNet121(include_top=False, pooling='avg', weights='imagenet')

features, filenames = [], []

print("Extracting features...")

for fname in tqdm(os.listdir(DATA_PATH)):
    fpath = os.path.join(DATA_PATH, fname)
    img = image.load_img(fpath, target_size=(IMG_SIZE, IMG_SIZE))
    x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))
    feat = base_model.predict(x, verbose=0)
    features.append(feat[0])
    filenames.append(fname)

features = np.array(features)
print("Feature shape:", features.shape)


NUM_CLUSTERS = 2
kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42)
clusters = kmeans.fit_predict(features)

print("Clusters found:", np.unique(clusters))

plt.figure(figsize=(6, 4))
sns.countplot(x=clusters)
plt.title("Cluster Distribution (KMeans)")
plt.xlabel("Cluster ID")
plt.ylabel("Number of Images")
plt.savefig("/kaggle/working/cluster_distribution.png")
plt.show()

print("Running t-SNE (this may take 1â€“2 minutes)...")

tsne = TSNE(n_components=2, random_state=42, perplexity=30)
tsne_features = tsne.fit_transform(features)

plt.figure(figsize=(7, 6))
sns.scatterplot(
    x=tsne_features[:, 0],
    y=tsne_features[:, 1],
    hue=clusters,
    palette="viridis",
    s=40
)
plt.title("t-SNE Visualization of Image Clusters")
plt.savefig("/kaggle/working/tsne_clusters.png")
plt.show()

for c in range(NUM_CLUSTERS):
    os.makedirs(f"{OUTPUT_PATH}/cluster_{c}", exist_ok=True)

for fname, cluster_id in zip(filenames, clusters):
    src = os.path.join(DATA_PATH, fname)
    dst = os.path.join(f"{OUTPUT_PATH}/cluster_{cluster_id}", fname)
    shutil.copy(src, dst)

print("Files moved into clustered folders!")

datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_gen = datagen.flow_from_directory(
    OUTPUT_PATH,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=32,
    class_mode="categorical",
    subset="training"
)

val_gen = datagen.flow_from_directory(
    OUTPUT_PATH,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=32,
    class_mode="categorical",
    subset="validation"
)

num_classes = train_gen.num_classes
print("Classes:", train_gen.class_indices)

base_model = DenseNet121(include_top=False, weights="imagenet", pooling="avg", input_shape=(224, 224, 3))
base_model.trainable = False

x = Dense(256, activation="relu")(base_model.output)
x = Dropout(0.3)(x)
output = Dense(num_classes, activation="softmax")(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer=Adam(1e-4), loss="categorical_crossentropy", metrics=["accuracy"])
model.summary()

checkpoint = ModelCheckpoint("best_model.h5", save_best_only=True, monitor="val_accuracy", verbose=1)
early_stop = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor="val_loss", factor=0.3, patience=2, verbose=1)

history = model.fit(train_gen, validation_data=val_gen, epochs=10,
                    callbacks=[checkpoint, early_stop, reduce_lr])

def plot_training_curves(history, label_prefix="Stage 1"):
    plt.figure(figsize=(12, 5))

    # Loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history["loss"], label="Train Loss")
    plt.plot(history.history["val_loss"], label="Val Loss")
    plt.title(f"{label_prefix} - Loss")
    plt.legend()

    # Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history["accuracy"], label="Train Accuracy")
    plt.plot(history.history["val_accuracy"], label="Val Accuracy")
    plt.title(f"{label_prefix} - Accuracy")
    plt.legend()

    plt.savefig(f"/kaggle/working/{label_prefix.lower().replace(' ', '_')}_curves.png")
    plt.show()

plot_training_curves(history, "Stage 1")

base_model.trainable = True
model.compile(optimizer=Adam(1e-5), loss="categorical_crossentropy", metrics=["accuracy"])

history_ft = model.fit(train_gen, validation_data=val_gen, epochs=10,
                       callbacks=[checkpoint, early_stop, reduce_lr])

plot_training_curves(history_ft, "Fine-Tuning")

print("Generating Confusion Matrix...")

val_gen.reset()
preds = model.predict(val_gen)
pred_labels = np.argmax(preds, axis=1)
true_labels = val_gen.classes

cm = confusion_matrix(true_labels, pred_labels)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=list(train_gen.class_indices.keys()),
            yticklabels=list(train_gen.class_indices.keys()))
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.savefig("/kaggle/working/confusion_matrix.png")
plt.show()

model.save("final_ovarian_densenet121.h5")
print("ðŸŽ‰ Training complete. Model saved successfully!")
